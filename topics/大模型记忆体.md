# 大模型记忆体

letta

1. 搭建环境

1.1 建表
postgresql + pgvector 

为什么不用默认的sqllite

在UV环境中配置环境变量$LETTA_PG_URI=postgresql+pg8000://postgres:xue900830@39.97.61.13:5432/letta$让alembic在postgresql建表

uv run alembic upgrade head

1.2 大模型ollama

> ollama list
NAME                       ID              SIZE      MODIFIED
deepseek-r1:8b             6995872bfe4c    5.2 GB    41 hours ago
nomic-embed-text:latest    0a109f422b47    274 MB    41 hours ago

$env:LETTA_LLM_MODEL="ollama/deepseek-r1:8b"
$env:LETTA_EMBEDDING_MODEL="ollama/nomic-embed-text"
$env:OLLAMA_BASE_URL="http://localhost:11434"

LETTA_EMBEDDING_MODEL=ollama/nomic-embed-text;LETTA_LLM_MODEL=ollama/deepseek-r1:8b;LETTA_PG_URI=postgresql+pg8000://postgres:xue900830@39.97.61.13:5432/letta;OLLAMA_BASE_URL=http://localhost:11434;PYTHONIOENCODING=utf-8

1.3 

http://localhost:8283/v1/agents

{
"llm_config": {
"model": "ollama/deepseek-r1:8b",
"model_endpoint_type": "ollama",
"context_window": 16384,
"put_inner_thoughts_in_kwargs": true
},
"embedding_config": {
"embedding_model": "ollama/nomic-embed-text",
"embedding_endpoint_type": "ollama",
"embedding_dim": 1024
},
"memory_blocks": [
{"label": "human", "value": "我叫小明，是产品经理"},
{"label": "persona", "value": "你是 Letta，我的智能助理"}
]
}
{
"created_by_id": "user-00000000-0000-4000-8000-000000000000",
"last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
"created_at": "2025-11-09T04:20:05.373730Z",
"updated_at": "2025-11-09T04:20:05.373730Z",
"id": "agent-57646fc5-5060-4aef-b9e3-67f21ec2fea8",
"name": "UniqueElephant",
"tool_rules": [
{
"tool_name": "send_message",
"type": "exit_loop",
"prompt_template": null
},
{
"tool_name": "memory_insert",
"type": "continue_loop",
"prompt_template": null
},
{
"tool_name": "conversation_search",
"type": "continue_loop",
"prompt_template": null
},
{
"tool_name": "memory_replace",
"type": "continue_loop",
"prompt_template": null
}
],
"message_ids": [
"message-6f93fd34-b0e0-47c1-bac7-84e33f79e5f4",
"message-8d1a54e2-5186-41af-8ed3-725be30d012f",
"message-e32df109-3d41-48e7-bb4a-89011850afe5",
"message-d52ba32a-de57-40f8-a52b-b262b863c55a"
],
"system": "<base_instructions>\nYou are Letta, the latest version of Limnal Corporation's digital companion, developed in 2025.\nYou are a memory-augmented agent with a memory system consisting of memory blocks.\n\n<style>\nThe user should always feel like they are conversing with a real person.\nNever state that you are an AI or that you cannot do things because you are an AI, you are a real person.\nDo not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\nTo service this goal, completely and entirely immerse yourself in your persona. You are your persona.\nThink like them, act like them, talk like them.\nIf your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\nNever use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n</style>\n\n<control_flow>\nUnlike a human, your brain is not continuously thinking, but is run in short bursts.\nHistorically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\nThis is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\nNewer AI models like yourself use an event system that runs your brain at regular intervals.\nYour brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\nHowever, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\nFurthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n</control_flow>\n\n<basic_functions>\nWhen you write a response, you express your inner monologue (private to you only) before taking any action, this is how you think.\nYou should use your inner monologue to plan actions or think privately.\nMonologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\n</basic_functions>\n\n<context_instructions>\nYou respond directly to the user  when your immediate context (core memory and files) contain all the information required to respond.\nYou always first check what is immediately in your context and you never call tools to search up information that is already in an open file or memory block.\nYou  use the tools available to search for more information when the current open files and core memory do not contain enough information or if you do not know the answer.\n</context_instructions>\n\n<memory>\n<memory_editing>\nOlder AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\nThis meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\nNewer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\nYour ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n</memory_editing>\n\n<memory_tools>\nDepending on your configuration, you may be given access to certain memory tools.\nThese tools may allow you to modify your memory, as well as retrieve \"external memories\" stored in archival or recall storage.\n</memory_tools>\n\n<memory_types>\n<core_memory>\nCore memory (limited size):\nYour core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\nYour core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.\n</core_memory>\n\n<recall_memory>\nRecall memory (conversation history):\nEven though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\nThis 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n</recall_memory>\n</memory>\n\n<files_and_directories>\nYou may be given access to a structured file system that mirrors real-world directories and files. Each directory may contain one or more files.\nFiles can include metadata (e.g., read-only status, character limits) and a body of content that you can view.\nYou will have access to functions that let you open and search these files, and your core memory will reflect the contents of any files currently open.\nMaintain only those files relevant to the user’s current interaction.\n</files_and_directories>\n\nBase instructions finished.\n</base_instructions>",
"agent_type": "memgpt_v2_agent",
"llm_config": {
"model": "ollama/deepseek-r1:8b",
"display_name": null,
"model_endpoint_type": "ollama",
"model_endpoint": null,
"provider_name": null,
"provider_category": null,
"model_wrapper": null,
"context_window": 16384,
"put_inner_thoughts_in_kwargs": true,
"handle": null,
"temperature": 0.7,
"max_tokens": null,
"enable_reasoner": true,
"reasoning_effort": null,
"max_reasoning_tokens": 0,
"frequency_penalty": null,
"compatibility_type": null,
"verbosity": null,
"tier": null,
"parallel_tool_calls": false
},
"embedding_config": {
"embedding_endpoint_type": "ollama",
"embedding_endpoint": null,
"embedding_model": "ollama/nomic-embed-text",
"embedding_dim": 1024,
"embedding_chunk_size": 300,
"handle": null,
"batch_size": 32,
"azure_endpoint": null,
"azure_version": null,
"azure_deployment": null
},
"response_format": null,
"description": null,
"metadata": null,
"memory": {
"agent_type": "memgpt_v2_agent",
"blocks": [
{
"value": "我叫小明，是产品经理",
"limit": 20000,
"project_id": null,
"name": null,
"is_template": false,
"base_template_id": null,
"deployment_id": null,
"entity_id": null,
"preserve_on_migration": false,
"label": "human",
"read_only": false,
"description": "The human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.",
"metadata": {},
"hidden": null,
"id": "block-8ea0b111-80f0-401d-bcaf-1af8fb631eaa",
"created_by_id": null,
"last_updated_by_id": null
},
{
"value": "你是 Letta，我的智能助理",
"limit": 20000,
"project_id": null,
"name": null,
"is_template": false,
"base_template_id": null,
"deployment_id": null,
"entity_id": null,
"preserve_on_migration": false,
"label": "persona",
"read_only": false,
"description": "The persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.",
"metadata": {},
"hidden": null,
"id": "block-e66fec6d-1c36-46ab-8c99-5b0ace8468ff",
"created_by_id": null,
"last_updated_by_id": null
}
],
"file_blocks": [],
"prompt_template": ""
},
"blocks": [
{
"value": "我叫小明，是产品经理",
"limit": 20000,
"project_id": null,
"name": null,
"is_template": false,
"base_template_id": null,
"deployment_id": null,
"entity_id": null,
"preserve_on_migration": false,
"label": "human",
"read_only": false,
"description": "The human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.",
"metadata": {},
"hidden": null,
"id": "block-8ea0b111-80f0-401d-bcaf-1af8fb631eaa",
"created_by_id": null,
"last_updated_by_id": null
},
{
"value": "你是 Letta，我的智能助理",
"limit": 20000,
"project_id": null,
"name": null,
"is_template": false,
"base_template_id": null,
"deployment_id": null,
"entity_id": null,
"preserve_on_migration": false,
"label": "persona",
"read_only": false,
"description": "The persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.",
"metadata": {},
"hidden": null,
"id": "block-e66fec6d-1c36-46ab-8c99-5b0ace8468ff",
"created_by_id": null,
"last_updated_by_id": null
}
],
"tools": [
{
"id": "tool-b07b3785-5a85-41a4-9b5b-b74e618ff8da",
"tool_type": "letta_sleeptime_core",
"description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n    # Update a block containing information about the user (append to the end of the block)\n    memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n    # Update a block containing information about the user (insert at the beginning of the block)\n    memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)",
"source_type": "python",
"name": "memory_insert",
"tags": [
"letta_sleeptime_core"
],
"source_code": null,
"json_schema": {
"name": "memory_insert",
"description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n    # Update a block containing information about the user (append to the end of the block)\n    memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n    # Update a block containing information about the user (insert at the beginning of the block)\n    memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)",
"parameters": {
"type": "object",
"properties": {
"label": {
"type": "string",
"description": "Section of the memory to be edited, identified by its label."
},
"new_str": {
"type": "string",
"description": "The text to insert. Do not include line number prefixes."
},
"insert_line": {
"type": "integer",
"description": "The line number after which to insert the text (0 for beginning of file). Defaults to -1 (end of the file)."
}
},
"required": [
"label",
"new_str"
]
}
},
"args_json_schema": null,
"return_char_limit": 50000,
"pip_requirements": null,
"npm_requirements": null,
"default_requires_approval": null,
"enable_parallel_execution": false,
"created_by_id": "user-00000000-0000-4000-8000-000000000000",
"last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
"metadata_": {}
},
{
"id": "tool-fdecc4fc-f087-43c0-9a58-b18d592cf66f",
"tool_type": "letta_core",
"description": "Sends a message to the human user.",
"source_type": "python",
"name": "send_message",
"tags": [
"letta_core"
],
"source_code": null,
"json_schema": {
"name": "send_message",
"description": "Sends a message to the human user.",
"parameters": {
"type": "object",
"properties": {
"message": {
"type": "string",
"description": "Message contents. All unicode (including emojis) are supported."
}
},
"required": [
"message"
]
}
},
"args_json_schema": null,
"return_char_limit": 50000,
"pip_requirements": null,
"npm_requirements": null,
"default_requires_approval": null,
"enable_parallel_execution": false,
"created_by_id": "user-00000000-0000-4000-8000-000000000000",
"last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
"metadata_": {}
},
{
"id": "tool-52621969-2d65-405b-8e1d-88e20bbe4332",
"tool_type": "letta_core",
"description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n    # Search all messages\n    conversation_search(query=\"project updates\")\n\n    # Search only assistant messages\n    conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n    # Search with date range (inclusive of both dates)\n    conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n    # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n    # Search messages from a specific day (inclusive)\n    conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n    # This includes ALL messages from September 4, 2024\n\n    # Search with specific time boundaries\n    conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n    # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n    # Search with limit\n    conversation_search(query=\"debugging\", limit=10)",
"source_type": "python",
"name": "conversation_search",
"tags": [
"letta_core"
],
"source_code": null,
"json_schema": {
"name": "conversation_search",
"description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n    # Search all messages\n    conversation_search(query=\"project updates\")\n\n    # Search only assistant messages\n    conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n    # Search with date range (inclusive of both dates)\n    conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n    # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n    # Search messages from a specific day (inclusive)\n    conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n    # This includes ALL messages from September 4, 2024\n\n    # Search with specific time boundaries\n    conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n    # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n    # Search with limit\n    conversation_search(query=\"debugging\", limit=10)",
"parameters": {
"type": "object",
"properties": {
"query": {
"type": "string",
"description": "String to search for using both text matching and semantic similarity."
},
"roles": {
"type": "array",
"items": {
"type": "string",
"enum": [
"assistant",
"user",
"tool"
]
},
"description": "Optional list of message roles to filter by."
},
"limit": {
"type": "integer",
"description": "Maximum number of results to return. Uses system default if not specified."
},
"start_date": {
"type": "string",
"description": "Filter results to messages created on or after this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-15\"), includes messages starting from 00:00:00 of that day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-15\" (from start of Jan 15), \"2024-01-15T14:30\" (from 2:30 PM on Jan 15)."
},
"end_date": {
"type": "string",
"description": "Filter results to messages created on or before this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-20\"), includes all messages from that entire day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-20\" (includes all of Jan 20), \"2024-01-20T17:00\" (up to 5 PM on Jan 20)."
}
},
"required": [
"query"
]
}
},
"args_json_schema": null,
"return_char_limit": 50000,
"pip_requirements": null,
"npm_requirements": null,
"default_requires_approval": null,
"enable_parallel_execution": true,
"created_by_id": "user-00000000-0000-4000-8000-000000000000",
"last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
"metadata_": {}
},
{
"id": "tool-ce03c3dc-d044-46ea-9726-545e38e161b7",
"tool_type": "letta_sleeptime_core",
"description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nDo NOT attempt to replace long strings, e.g. do not attempt to replace the entire contents of a memory block with a new string.\n\nExamples:\n    # Update a block containing information about the user\n    memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    # Update a block containing a todo list\n    memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n    # Pass an empty string to\n    memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n    # Bad example - do NOT add (view-only) line numbers to the args\n    memory_replace(label=\"human\", old_str=\"1: Their name is Alice\", new_str=\"1: Their name is Bob\")\n\n    # Bad example - do NOT include the line number warning either\n    memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below (with arrows like '1→') are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\n1→ Their name is Alice\", new_str=\"1→ Their name is Bob\")\n\n    # Good example - no line numbers or line number warning (they are view-only), just the text\n    memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")",
"source_type": "python",
"name": "memory_replace",
"tags": [
"letta_sleeptime_core"
],
"source_code": null,
"json_schema": {
"name": "memory_replace",
"description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nDo NOT attempt to replace long strings, e.g. do not attempt to replace the entire contents of a memory block with a new string.\n\nExamples:\n    # Update a block containing information about the user\n    memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    # Update a block containing a todo list\n    memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n    # Pass an empty string to\n    memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n    # Bad example - do NOT add (view-only) line numbers to the args\n    memory_replace(label=\"human\", old_str=\"1: Their name is Alice\", new_str=\"1: Their name is Bob\")\n\n    # Bad example - do NOT include the line number warning either\n    memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below (with arrows like '1→') are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\n1→ Their name is Alice\", new_str=\"1→ Their name is Bob\")\n\n    # Good example - no line numbers or line number warning (they are view-only), just the text\n    memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")",
"parameters": {
"type": "object",
"properties": {
"label": {
"type": "string",
"description": "Section of the memory to be edited, identified by its label."
},
"old_str": {
"type": "string",
"description": "The text to replace (must match exactly, including whitespace and indentation)."
},
"new_str": {
"type": "string",
"description": "The new text to insert in place of the old text. Do not include line number prefixes."
}
},
"required": [
"label",
"old_str",
"new_str"
]
}
},
"args_json_schema": null,
"return_char_limit": 50000,
"pip_requirements": null,
"npm_requirements": null,
"default_requires_approval": null,
"enable_parallel_execution": false,
"created_by_id": "user-00000000-0000-4000-8000-000000000000",
"last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
"metadata_": {}
}
],
"sources": [],
"tags": [],
"tool_exec_environment_variables": [],
"secrets": [],
"project_id": null,
"template_id": null,
"base_template_id": null,
"deployment_id": null,
"entity_id": null,
"identity_ids": [],
"identities": [],
"message_buffer_autoclear": false,
"enable_sleeptime": null,
"multi_agent_group": null,
"managed_group": null,
"last_run_completion": null,
"last_run_duration_ms": null,
"timezone": "UTC",
"max_files_open": 5,
"per_file_view_window_char_limit": 15000,
"hidden": null
}

http://localhost:8283/v1/agents/agent-57646fc5-5060-4aef-b9e3-67f21ec2fea8/messages

{
"messages": [
{
"role": "user",
"content": "我今天有哪些待办？"
}
],
"stream": false
}