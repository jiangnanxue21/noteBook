# 分布式

## CAP理论
CAP 理论对分布式系统的特性做了高度抽象，形成了三个指标
- Consistency

  一致性说的是客户端的每次读操作，不管访问哪个节点，要么读到的都是同一份最新写入的数据，要么读取失败

- Availability

   可用性说的是任何来自客户端的请求，不管访问哪个非故障节点，都能得到响应数据，但不保证是同一份最新数据

- Partition Tolerance

   当节点间出现任意数量的消息丢失或高延迟的时候，系统仍然在继续工作。也就是说，分布式系统在告诉访问本系统的客户端：不管我的内部出现什么样的数据同步问题，我会一直运行。这个指标，强调的是集群对分区故障的容错能力
   
   因为分布式系统与单机系统不同，它涉及到多节点间的通讯和交互，节点间的分区故障是必然发生的，在分布式系统中分区容错性是必须要考虑的

大部分人对CAP理论有个误解，认为无论在什么情况下，分布式系统都只能在C和A中选择1个。其实，在不存在网络分区的情况下，也就是分布式系统正常运行时（这也是系统在绝大部分时候所处的状态），就是说在不需要 P 时，C 和 A 能够同时保证。只有当发生分区故障的时候，也就是说需要 P 时，才会在 C 和 A 之间做出选择。而且如果读操作会读到旧数据，影响到了系统运行或业务运行（也就是说会有负面的影响），推荐选择 C，否则选 A

- 如何使用CAP

只要有网络交互就一定会有延迟和数据丢失，而这种状况我们必须接受，还必须保证系统不能挂掉。所以就像我上面提到的，节点间的分区故障是必然发生的。也就是说，分区容错性（P）是前提，是必须要保证的

- 样例

InfluxDB是由META节点和DATA节点2个逻辑单元组成，这2个节点的功能和数据特点不同，需要我们分别为它们设计分区容错一致性模型

1. 考虑到META节点保存的是系统运行的关键元信息，**采用CP架构**
2. DATA节点保存的是具体的时序数据记录，服务会被访问频繁，水平扩展、性能、可用性等是关键，**采用AP架构**

- CP模型：典型的应用是 Etcd，Consul和Hbase
- AP模型：典型应用就比如Cassandra和DynamoDB


## Paxos算法

### Basic Paxos算法

**描述的是多节点之间如何就某个值达成共识**

使用了比较重要的概念：提案、准备（Prepare）请求、接受（Accept）请求、角色

![](basicPaxos.png)

1. 角色
   - 提议者（Proposer）: 代表的是接入和协调功能，收到客户端请求后，发起二阶段提交，进行共识协商
   - 接受者（Acceptor）: 接受者代表投票协商和存储数据，对提议的值进行投票，并接受达成共识的值，存储保存
   - 学习者（Learner）
2. 提案
3. 准备（Prepare）请求
    - 提案编号，编号越大的优先级越高
4. 接受（Accept）请求
    - 就是需要达成共识的value投票

Basic Paxos的**容错能力**，源自“大多数”的约定，你可以这么理解：当少于一半的节点出现故障的时候，共识协商仍然在正常工作

- 思考:

如果节点 A、B 已经通过了提案[5, 7]，节点 C 未通过任何提案，那么当客户端 3 提案编号为 9 时，通过 Basic Paxos 执行“SET X = 6”，最终三个节点上 X 值是多少呢？

如果节点 A、B 已经通过了提案[5, 7]，节点 C 未通过任何提案，那么当客户端 3 提案编号为 9 ，通过 Basic Paxos 执行“SET X = 6”, 最终节点值应该是[9,7], 过程如下：
1. 在准备阶段，节点C收到客户端3的准备请求[9,6], 因为节点C未收到任何提案，所以返回“尚无提案”的相应。这时如果节点C收到了之前客户端的准备请求[5, 7], 根据提案编号5小于它之前响应的准备请求的提案编号9，会丢弃该准备请求。
2. 客户端3发送准备请求[9,6]给节点A，B，这时因为节点A，B已经通过了提案[5,7], 根据“如果接受者之前有通过提案，那么接受者将承诺，会在准备请求的响应中，包含已经通过的最大编号的提案信息”，节点A，B会返回[5,7]给客户端3.
3. 客户端3发送会接受请求[9,7]给节点A，B，C（注意这里使用的是准备阶段的最大提议编号和已经被通过的值），因为此时请求编号9不小于之前的请求编号，所以所有节点接受该请求[9,7].
4. 所有学习者会接受该提案，学习该值

**对一个key如果达成共识，后面该key的值也不会变了**


### Multi Paxos算法
   Multi-Paxos 算法是一个统称，它是指基于 Multi-Paxos 思想，通过多个 Basic Paxos 实例实现一系列值的共识的算法（比如 Chubby 的 Multi-Paxos 实现、Raft 算法等）

Basic Paxos是通过二阶段提交来达成共识的。在第一阶段，也就是准备阶段，接收到大多数准备响应的提议者，才能发起接受请求进入第二阶段（也就是接受阶段）

Basic Paxos的问题：

1. 如果多个提议者同时提交提案，可能出现因为提案编号冲突，在准备阶段没有提议者接收到大多数准备响应，协商失败，需要重新协商。一个5节点的集群，如果3个节点作为提议者同时提案，就可能发生因为没有提议者接收大多数响应（比如1个提议者接收到1个准备响应，另外2个提议者分别接收到2个准备响应）而准备失败，需要重新协商
2. 2轮RPC 通讯（准备阶段和接受阶段）往返消息多、耗性能、延迟大

## Quorum NWR算法

- N: 表示副本数，又叫做复制因子（Replication Factor）
- W，又称写一致性级别（Write Consistency Level），表示成功完成 W 个副本更新，才完成写操作
- R，又称读一致性级别（Read Consistency Level）

